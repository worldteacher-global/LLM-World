{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain (Legacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubAgents\n",
    "\n",
    "from langchain.tools import tool\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def calculate_PC(data):\n",
    "    '''\n",
    "    Calculate the principal components of the input data\n",
    "    '''\n",
    "    mu = data.to_numpy().mean(axis=0)\n",
    "    std = data.to_numpy().std(axis=0)\n",
    "\n",
    "    standardized_data = (data.to_numpy()-mu)/std\n",
    "    cov_matrix = np.cov(standardized_data, rowvar=False)\n",
    "\n",
    "    eigenvalue,eigenvector = eigh(cov_matrix)\n",
    "    eigenvalue = eigenvalue[::-1]\n",
    "    eigenvector = eigenvector[:,::-1]\n",
    "\n",
    "    # Apply 1st 2 principal components to the dataset\n",
    "    transformed_data = standardized_data @ np.vstack((eigenvector[:,0], eigenvector[:,1])).T\n",
    "    \n",
    "    pc1 = transformed_data[:,0].tolist()\n",
    "    pc2 = transformed_data[:,1].tolist()\n",
    "\n",
    "    return [pc1,pc2] \n",
    "\n",
    "\n",
    "def levene_test(data):\n",
    "    ''' \n",
    "    Calculate the equality of variances for 2 or more groups | F(1-aplha, N-k)\n",
    "    \n",
    "    Args:\n",
    "    data (pd.dataframe): dataframe of groups\n",
    "    k (int): numner of different groups to which the sampled case belong\n",
    "    N (int): total number of cases in all groups\n",
    "    Ni (int): number of cases in the ith group\n",
    "    Yij (array): the value of the measured variable for the jth case from the ith group\n",
    "    Zij (float): the mean or median of the ith group\n",
    "    Zi (float): is the mean of the Zij for group i\n",
    "    Z (float): is the mean of all Zij\n",
    "\n",
    "    Return:\n",
    "    W (float): F statistic 0.05\n",
    "    pval (float): p value\n",
    "    '''\n",
    "    data = np.array(data).T\n",
    "\n",
    "    N = data.shape[0]*data.shape[1]\n",
    "    k = data.shape[1]\n",
    "    Ni = data.shape[0]\n",
    "\n",
    "    Zij = [np.abs(data.T[i]-data.T[i].mean()) for i in range(k)]\n",
    "\n",
    "    Zi = [np.divide(1,Ni)*np.sum(Zij[i]) for i in range(k)]\n",
    "\n",
    "    Z = np.divide(1,N)*np.sum([np.sum(Zij[i]) for i in range(k)])\n",
    "\n",
    "    W = np.divide((N-k),(k-1))*np.divide(np.sum(Ni*(Zi-Z)**2),np.sum([np.sum((Zij[i]-Zi[i])**2) for i in range(k)]))\n",
    "    \n",
    "    pval = 1-f.cdf(W,k-1,N-k)\n",
    "\n",
    "    return W, pval\n",
    "\n",
    "def anova_one_way(dd):\n",
    "    '''     \n",
    "    Args:\n",
    "    X (float): overall mean\n",
    "    Xj (float): mean of group j\n",
    "    n (int): sample size of group j\n",
    "    Xij = the ith observation in group j\n",
    "\n",
    "    '''\n",
    "\n",
    "    k = dd.shape[1]\n",
    "    n = dd.shape[0]\n",
    "    N = k*n\n",
    "\n",
    "    X = np.array([dd[col].mean() for col in dd.columns]).mean()\n",
    "    Xj = np.array([dd[col].mean() for col in dd.columns])\n",
    "    Xij = np.array([dd[col]for col in dd.columns])\n",
    "\n",
    "    SSR = n*np.sum((Xj-X)**2) # Regression sum of squares\n",
    "    SSE = np.sum([np.sum((Xij[i]-Xj[i])**2) for i in range(len(Xj))]) # Error sum of squares\n",
    "    SST = SSR+SSE # Total sum of squares\n",
    "\n",
    "    df1 = k-1\n",
    "    df2 = N-k\n",
    "\n",
    "    MS = SSR/df1 # Mean squares\n",
    "    MSE = SSE/df2 # Mean square error\n",
    "    F = MS/MSE # F-statistic\n",
    "    pval = 1-f.cdf(F,k-1,N-k)\n",
    "    return F, pval\n",
    "\n",
    "@tool\n",
    "def get_columns(col_input) -> list:\n",
    "    '''\n",
    "    Pull columns to perform statistics on\n",
    "    '''\n",
    "    if col_input == \"all\" or \"*\":\n",
    "       \n",
    "        columns = df.columns.to_list()\n",
    "        return columns\n",
    "\n",
    "@tool\n",
    "def covariance_tool(columns: str):\n",
    "    '''\n",
    "    Calculate the covariance of the columns of data \n",
    "\n",
    "    Args:\n",
    "    columns (str): list of columns to perform covariance calculation\n",
    "\n",
    "    Return:\n",
    "    Response with the calculated covariance matrix\n",
    "    '''\n",
    "\n",
    "    columns = [col.strip().strip('\"').strip(\"'\") for col in columns.split(',')]\n",
    "\n",
    "    \n",
    "    missing = [col for col in columns if col not in df.columns]\n",
    "    if missing:\n",
    "        return f'Columns not found: {','.join(missing)}'\n",
    "    cov_matrix = df[columns].cov()\n",
    "    return f' Covariance Matrix: \\n{cov_matrix.to_string()}'\n",
    "\n",
    "@tool\n",
    "def correlation_tool(columns: str):\n",
    "    '''\n",
    "    Calculate the correlation of the columns of data\n",
    "\n",
    "    Args:\n",
    "    columns (str): list of columns to perform correlation calculation on\n",
    "\n",
    "    Return:\n",
    "    Response with the calculated correlation matrix\n",
    "    '''\n",
    "\n",
    "    columns = [col.strip().strip('\"').strip(\"'\") for col in columns.split(',')]\n",
    "\n",
    "    missing = [col for col in columns if col not in df.columns]\n",
    "    if missing:\n",
    "        return f'Columns not found: {','.join(missing)}'\n",
    "    corr_matrix = df[columns].corr()\n",
    "    return f'Correlation Matrix: {corr_matrix.to_string()}'\n",
    "\n",
    "@tool\n",
    "def normality_tool(columns: str):\n",
    "    '''\n",
    "    Calculate if the input data is normal\n",
    "\n",
    "    Args:\n",
    "    df (pd.dataframe): dataframe containig raw data\n",
    "\n",
    "    Return:\n",
    "    Response on whether data is normal or not, explicitly stating which columns are not\n",
    "    '''\n",
    "\n",
    "    columns = [col.strip().strip('\"').strip(\"'\") for col in columns.split(',')]\n",
    "\n",
    "    missing = [col for col in columns if col not in df.columns]\n",
    "    if missing:\n",
    "        return f'Columns not found: {','.join(missing)}'\n",
    "\n",
    "    not_normal = []\n",
    "\n",
    "    for col in columns:\n",
    "        tstat, pval = shapiro(df[col])\n",
    "        if pval < 0.05: # reject H0\n",
    "            not_normal.append(col)\n",
    "            return f'Column {col} is not normally distributed, and not recommended to include in ANOVA analysis'\n",
    "    return f'Data is normal'\n",
    "\n",
    "@tool\n",
    "def levene_test_tool(columns: str):\n",
    "    ''' \n",
    "    Calculate the equality of variances for 2 or more groups | F(1-aplha, N-k)\n",
    "    '''\n",
    "\n",
    "    columns = [col.strip().strip('\"').strip(\"'\") for col in columns.split(',')]\n",
    "\n",
    "    missing = [col for col in columns if col not in df.columns]\n",
    "    if missing:\n",
    "        return f'Columns not found: {','.join(missing)}'\n",
    "    \n",
    "\n",
    "    data = df[columns]\n",
    "    \n",
    "\n",
    "    return levene_test(data)\n",
    "\n",
    "@tool    \n",
    "def calculate_ANOVA_tool(columns: str):\n",
    "    '''\n",
    "    Compare the means of 3 or more independant groups to determine statistical difference between popuplaiton means.\n",
    "    H0: The mean of the independent groups are all the same, there is no statistical difference. difference is due to random sampling from same population\n",
    "    Test for normality within ea group with shapiro-wilks test (H0: data was drawn from a normal distribution) pval < 0.05 reject H0\n",
    "    Test for homegenity of variance with levene test (H0: data has equal variance) p_val < 0.05 reject H0 at lease 1 of the groups is not heteroskedastic Anova can be used\n",
    "    H0: two or more groups have the same population mean\n",
    "    Calculate the amount of variance between groups means to the amount of variation within each group  group variation > within group variation => difference in mean not random\n",
    "    '''\n",
    "\n",
    "    columns = [col.strip().strip('\"').strip(\"'\") for col in columns.split(',')]\n",
    "\n",
    "    missing = [col for col in columns if col not in df.columns]\n",
    "    if missing:\n",
    "        return f'Columns not found: {','.join(missing)}'\n",
    "    \n",
    "\n",
    "    data = df[columns]\n",
    "    \n",
    "\n",
    "    return anova_one_way(data)\n",
    "\n",
    "@tool\n",
    "def PCA_tool(columns: str) ->list:\n",
    "    '''\n",
    "    Calculates the 1st two principal components of a dataset\n",
    "    '''\n",
    "\n",
    "    columns = [col.strip().strip('\"').strip(\"'\") for col in columns.split(',')]\n",
    "\n",
    "    \n",
    "    return calculate_PC(df[columns])\n",
    "\n",
    "@tool\n",
    "def plot_data(mylist: str):\n",
    "    '''\n",
    "    Create a scatter plot \n",
    "    '''\n",
    "    import matplotlib.pyplot as plt \n",
    "    import ast\n",
    "    \n",
    "    mylist = mylist.strip('\" \"')\n",
    "    mylist = ast.literal_eval(mylist)\n",
    "    pc1 = np.array(mylist[0])\n",
    "    pc2 = np.array(mylist[1])\n",
    "\n",
    "\n",
    "\n",
    "    plt.scatter(pc1,pc2)\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    # plt.savefig(\"pca_result.png\")\n",
    "    plt.show()\n",
    "    return \"PCA plot saved to pca_result.png\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def stat_agent():\n",
    "    ''' \n",
    "    One-shot Stat Agent\n",
    "    '''\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_message=True)\n",
    "    llm = BedrockChat(model_id='anthropic.claude-3-5-sonnet-20240620-v1:0', region_name='us-east-1', model_kwargs={'max_tokens': 3000, 'temperature': 0})\n",
    "\n",
    "    sub_agent = [covariance_tool, correlation_tool, normality_tool, levene_test_tool, get_columns, calculate_ANOVA_tool, PCA_tool, plot_data]\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=sub_agent,\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        agent_kwargs={'system_message': 'You are a Statistics agent '}\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4651/2534861037.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_message=True)\n",
      "/tmp/ipykernel_4651/2534861037.py:10: LangChainDeprecationWarning: The class `BedrockChat` was deprecated in LangChain 0.0.34 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import ChatBedrock``.\n",
      "  llm = BedrockChat(model_id='anthropic.claude-3-5-sonnet-20240620-v1:0', region_name='us-east-1', model_kwargs={'max_tokens': 3000, 'temperature': 0})\n",
      "/tmp/ipykernel_4651/2534861037.py:14: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, we need to follow these steps:\n",
      "1. Get all the columns from the dataframe\n",
      "2. Calculate the principal components using those columns\n",
      "3. Create a scatter plot of the first two principal components\n",
      "\n",
      "Let's start with getting all the columns.\n",
      "\n",
      "Action: get_columns\n",
      "Action Input: all\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mGreat, we now have all the columns from the dataframe. Let's proceed with calculating the principal components using these columns.\n",
      "\n",
      "Action: PCA_tool\n",
      "Action Input: A0,A1,A2,A3,A4,A5,A6,A7,A8,A9,A10,A11,A12\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[[-0.8279801125859164, -1.8748439208408956, -0.9639972848511245, 1.7064715093789358, -3.674450747526948, 1.5901198630406577, -0.9601324619449182, -2.3963045488865466, 0.6049511023882346, 0.20410869888476968, 0.9799686007125502, -0.9871319474789318, -0.2531322066426445, 2.9761087256826713, 3.496544317832839, -0.04073974852588082, -0.18050710373411924, 0.3476974768882603, 3.519289973481336, -3.2660401852723435], [0.17702347901541626, 2.9740327864943628, -1.314219285745275, -1.4084897210219536, -2.7943212785441816, -0.7610190055223119, 1.8326953276131588, -0.3636056422527247, 2.258025982026305, 1.435574201873288, 0.3370210206542136, 2.248175394572511, 1.3893196802712418, 0.9293976662562928, 0.2599447823337278, -1.2119095046882802, -2.1700619763951288, -2.176387888541321, -1.3924040652248222, -0.24879195317454347]]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Great, we now have the first two principal components calculated. The next step is to create a scatter plot using these components.\n",
      "\n",
      "Action: plot_data\n",
      "Action Input: [-0.8279801125859164, -1.8748439208408956, -0.9639972848511245, 1.7064715093789358, -3.674450747526948, 1.5901198630406577, -0.9601324619449182, -2.3963045488865466, 0.6049511023882346, 0.20410869888476968, 0.9799686007125502, -0.9871319474789318, -0.2531322066426445, 2.9761087256826713, 3.496544317832839, -0.04073974852588082, -0.18050710373411924, 0.3476974768882603, 3.519289973481336, -3.2660401852723435],[0.17702347901541626, 2.9740327864943628, -1.314219285745275, -1.4084897210219536, -2.7943212785441816, -0.7610190055223119, 1.8326953276131588, -0.3636056422527247, 2.258025982026305, 1.435574201873288, 0.3370210206542136, 2.248175394572511, 1.3893196802712418, 0.9293976662562928, 0.2599447823337278, -1.2119095046882802, -2.1700619763951288, -2.176387888541321, -1.3924040652248222, -0.24879195317454347]\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mPCA plot saved to pca_result.png\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer. We have successfully completed all the required steps to answer the question.\n",
      "\n",
      "Final Answer: We have obtained all the columns from the dataframe, calculated the principal components using those columns, and created a scatter plot of the first two principal components. The process involved the following steps:\n",
      "\n",
      "1. We retrieved all the columns from the dataframe using the get_columns tool, which returned 13 columns (A0 to A12).\n",
      "\n",
      "2. We then used the PCA_tool to calculate the principal components using all these columns. This tool returned the first two principal components.\n",
      "\n",
      "3. Finally, we used the plot_data tool to create a scatter plot of these two principal components. The scatter plot has been saved as 'pca_result.png'.\n",
      "\n",
      "This scatter plot visualizes the data points in the space of the first two principal components, which represent the directions of maximum variance in the dataset. This can help in identifying patterns, clusters, or trends in the high-dimensional data that might not be apparent in the original feature space.\n",
      "\n",
      "You can now examine the 'pca_result.png' file to see the visual representation of your data in the principal component space.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Get all the columns from df and calculate the principal components then create a scatter plot of the 2 different principal components',\n",
       " 'chat_history': '',\n",
       " 'output': \"We have obtained all the columns from the dataframe, calculated the principal components using those columns, and created a scatter plot of the first two principal components. The process involved the following steps:\\n\\n1. We retrieved all the columns from the dataframe using the get_columns tool, which returned 13 columns (A0 to A12).\\n\\n2. We then used the PCA_tool to calculate the principal components using all these columns. This tool returned the first two principal components.\\n\\n3. Finally, we used the plot_data tool to create a scatter plot of these two principal components. The scatter plot has been saved as 'pca_result.png'.\\n\\nThis scatter plot visualizes the data points in the space of the first two principal components, which represent the directions of maximum variance in the dataset. This can help in identifying patterns, clusters, or trends in the high-dimensional data that might not be apparent in the original feature space.\\n\\nYou can now examine the 'pca_result.png' file to see the visual representation of your data in the principal component space.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "stat_agent = stat_agent()\n",
    "# df = pd.read_csv('sample_df.csv')\n",
    "data = load_wine()\n",
    "lbl = data['target_names']\n",
    "header = [a+str(n) for n,a in enumerate(np.repeat('A',data['data'].shape[1]))]\n",
    "df = pd.DataFrame(data['data'], columns=header)\n",
    "df = df.iloc[:20,:]\n",
    "\n",
    "stat_agent.invoke('Get all the columns from df and calculate the principal components then create a scatter plot of the 2 different principal components')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/\")\n",
    "sys.path.append('/home/sagemaker-user/user-default-efs/CLONED_REPOS/LLM-World/src/')\n",
    "import requests\n",
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "load_dotenv(\"/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/.env\")\n",
    "from langchain_aws import ChatBedrockConverse \n",
    "\n",
    "def get_openai_llms():\n",
    "    '''get a list of llms available in Azure OpenAI'''\n",
    "    response = requests.get(os.getenv('AZURE_OPENAI_BASEURL'))\n",
    "    returned_payload = response.json()\n",
    "\n",
    "    return [models for models in returned_payload['nonprod'].keys()]\n",
    "\n",
    "\n",
    "def get_aws_llms():\n",
    "    '''get a list of llms available in AWS Bedrock'''\n",
    "    bedrock_client = boto3.client('bedrock', region_name='us-east-1')\n",
    "\n",
    "    response = bedrock_client.list_foundation_models()\n",
    "\n",
    "    llm_dict = {}\n",
    "    for obj in  response['modelSummaries']:\n",
    "        llm_dict[obj['modelName']] = obj['modelId']\n",
    "\n",
    "    return llm_dict\n",
    "\n",
    "def aws_llm(modelid: str):  \n",
    "    '''Create LangChain Object for AWS Bedrock llm'''     \n",
    "\n",
    "    return ChatBedrockConverse(model_id=modelid, region_name='us-east-1')\n",
    "\n",
    "def openai_llm(modle_id: str):\n",
    "    '''Create LangChain LLM object for Azure OpenAI llm'''\n",
    "    api_response = requests.get(os.getenv('AZURE_OPENAI_BASEURL'))\n",
    "    payload = api_response.json()\n",
    "\n",
    "    gllm = AzureChatOpenAI(\n",
    "        deployment_name=modle_id,  \n",
    "        openai_api_version=\"2024-12-01-preview\",\n",
    "        azure_endpoint=payload['nonprod'][modle_id][0]['endpoint'],\n",
    "        api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
    "        temperature=0)\n",
    "    return gllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pegasus v1.2': 'twelvelabs.pegasus-1-2-v1:0', 'Claude Opus 4.1': 'anthropic.claude-opus-4-1-20250805-v1:0', 'Titan Text Large': 'amazon.titan-tg1-large', 'Titan Image Generator G1': 'amazon.titan-image-generator-v1', 'Titan Image Generator G1 v2': 'amazon.titan-image-generator-v2:0', 'Nova Premier': 'amazon.nova-premier-v1:0', 'Titan Text G1 - Premier': 'amazon.titan-text-premier-v1:0', 'Nova Pro': 'amazon.nova-pro-v1:0', 'Nova Lite': 'amazon.nova-lite-v1:0', 'Nova Canvas': 'amazon.nova-canvas-v1:0', 'Nova Reel': 'amazon.nova-reel-v1:1', 'Nova Micro': 'amazon.nova-micro-v1:0', 'Nova Sonic': 'amazon.nova-sonic-v1:0', 'Titan Text Embeddings v2': 'amazon.titan-embed-g1-text-02', 'Titan Text G1 - Lite': 'amazon.titan-text-lite-v1', 'Titan Text G1 - Express': 'amazon.titan-text-express-v1', 'Titan Embeddings G1 - Text': 'amazon.titan-embed-text-v1', 'Titan Text Embeddings V2': 'amazon.titan-embed-text-v2:0', 'Titan Multimodal Embeddings G1': 'amazon.titan-embed-image-v1', 'SDXL 1.0': 'stability.stable-diffusion-xl-v1', 'Jamba-Instruct': 'ai21.jamba-instruct-v1:0', 'Jamba 1.5 Large': 'ai21.jamba-1-5-large-v1:0', 'Jamba 1.5 Mini': 'ai21.jamba-1-5-mini-v1:0', 'Claude Instant': 'anthropic.claude-instant-v1', 'Claude': 'anthropic.claude-v2', 'Claude 3 Sonnet': 'anthropic.claude-3-sonnet-20240229-v1:0', 'Claude 3 Haiku': 'anthropic.claude-3-haiku-20240307-v1:0', 'Claude 3 Opus': 'anthropic.claude-3-opus-20240229-v1:0', 'Claude 3.5 Sonnet': 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'Claude 3.5 Sonnet v2': 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'Claude 3.7 Sonnet': 'anthropic.claude-3-7-sonnet-20250219-v1:0', 'Claude 3.5 Haiku': 'anthropic.claude-3-5-haiku-20241022-v1:0', 'Claude Opus 4': 'anthropic.claude-opus-4-20250514-v1:0', 'Claude Sonnet 4': 'anthropic.claude-sonnet-4-20250514-v1:0', 'Command R': 'cohere.command-r-v1:0', 'Command R+': 'cohere.command-r-plus-v1:0', 'Embed English': 'cohere.embed-english-v3', 'Embed Multilingual': 'cohere.embed-multilingual-v3', 'DeepSeek-R1': 'deepseek.r1-v1:0', 'Llama 3 8B Instruct': 'meta.llama3-8b-instruct-v1:0', 'Llama 3 70B Instruct': 'meta.llama3-70b-instruct-v1:0', 'Llama 3.1 8B Instruct': 'meta.llama3-1-8b-instruct-v1:0', 'Llama 3.1 70B Instruct': 'meta.llama3-1-70b-instruct-v1:0', 'Llama 3.2 11B Instruct': 'meta.llama3-2-11b-instruct-v1:0', 'Llama 3.2 90B Instruct': 'meta.llama3-2-90b-instruct-v1:0', 'Llama 3.2 1B Instruct': 'meta.llama3-2-1b-instruct-v1:0', 'Llama 3.2 3B Instruct': 'meta.llama3-2-3b-instruct-v1:0', 'Llama 3.3 70B Instruct': 'meta.llama3-3-70b-instruct-v1:0', 'Llama 4 Scout 17B Instruct': 'meta.llama4-scout-17b-instruct-v1:0', 'Llama 4 Maverick 17B Instruct': 'meta.llama4-maverick-17b-instruct-v1:0', 'Mistral 7B Instruct': 'mistral.mistral-7b-instruct-v0:2', 'Mixtral 8x7B Instruct': 'mistral.mixtral-8x7b-instruct-v0:1', 'Mistral Large (24.02)': 'mistral.mistral-large-2402-v1:0', 'Mistral Small (24.02)': 'mistral.mistral-small-2402-v1:0', 'Pixtral Large (25.02)': 'mistral.pixtral-large-2502-v1:0', 'Marengo Embed v2.7': 'twelvelabs.marengo-embed-2-7-v1:0'} \n",
      "\n",
      "['dall-e-3', 'gpt-35-turbo', 'gpt-35-turbo-instruct', 'gpt-4-turbo', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.5', 'gpt-4o-audio', 'gpt-4o-global', 'gpt-4o-mini-global', 'gpt-4o-regional', 'gpt-5', 'gpt-5-chat', 'gpt-5-mini', 'gpt-5-nano', 'gpt-image-1', 'model-router', 'o1', 'o1-mini', 'o3', 'o3-mini', 'o4-mini', 'text-embedding-3-large', 'text-embedding-3-small', 'text-embedding-ada-002'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_aws_llms(),'\\n')\n",
    "print(get_openai_llms(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatBedrockConverse(client=<botocore.client.BedrockRuntime object at 0x7ff8a52afda0>, model_id='anthropic.claude-sonnet-4-20250514-v1:0', region_name='us-east-1', provider='anthropic', supports_tool_choice_values=('auto', 'any', 'tool'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_llm(get_aws_llms()['Claude Sonnet 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from mytools import MyTools\n",
    "\n",
    "def stat_agent():\n",
    "    ''' \n",
    "    One-shot Stat Agent\n",
    "    '''\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_message=True)\n",
    "    # llm = openai_llm('gpt-4.1')\n",
    "    llm = aws_llm(get_aws_llms()['Claude Sonnet 4'])\n",
    "    mytools = MyTools()\n",
    "\n",
    "    # sub_agent = [covariance_tool, correlation_tool, normality_tool, levene_test_tool, get_columns, calculate_ANOVA_tool, PCA_tool, plot_data]\n",
    "    sub_agent = [mytools.covariance_tool, mytools.correlation_tool, mytools.normality_tool, mytools.levene_test, mytools.anova_one_way, mytools.calculate_PC, mytools.gen_plot]#, mytools.display_base64_image]\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=sub_agent,\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        agent_kwargs={'system_message': 'You are a Statistics agent'}\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('sample_df.csv')\n",
    "data = load_wine()\n",
    "lbl = data['target_names']\n",
    "header = [a+str(n) for n,a in enumerate(np.repeat('A',data['data'].shape[1]))]\n",
    "df = pd.DataFrame(data['data'], columns=header)\n",
    "df = df.iloc[:20,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the Converse operation: Invocation of model ID anthropic.claude-sonnet-4-20250514-v1:0 with on-demand throughput isn’t supported. Retry your request with the ID or ARN of an inference profile that contains this model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m stat_agent = stat_agent()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstat_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGet all the columns from df and calculate the principal components then create a scatter plot of the 2 different principal components\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/agents/agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/agents/agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/agents/agent.py:1352\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1349\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1351\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/agents/agent.py:800\u001b[39m, in \u001b[36mAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[32m    789\u001b[39m \n\u001b[32m    790\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    797\u001b[39m \u001b[33;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[32m    798\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    799\u001b[39m full_inputs = \u001b[38;5;28mself\u001b[39m.get_full_inputs(intermediate_steps, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m full_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfull_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_parser.parse(full_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/chains/llm.py:325\u001b[39m, in \u001b[36mLLMChain.predict\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    311\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[32m    312\u001b[39m \n\u001b[32m    313\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m \u001b[33;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.output_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:190\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    189\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/chains/base.py:410\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    379\u001b[39m \n\u001b[32m    380\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    403\u001b[39m config = {\n\u001b[32m    404\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    405\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    406\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    407\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    408\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/chains/llm.py:127\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    125\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain/chains/llm.py:139\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    137\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    146\u001b[39m     cast(\u001b[38;5;28mlist\u001b[39m, prompts),\n\u001b[32m    147\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks},\n\u001b[32m    148\u001b[39m )\n\u001b[32m    149\u001b[39m generations: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Generation]] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1006\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    997\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1003\u001b[39m     **kwargs: Any,\n\u001b[32m   1004\u001b[39m ) -> LLMResult:\n\u001b[32m   1005\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:825\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    823\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    824\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    831\u001b[39m         )\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    833\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1072\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1076\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/langchain_aws/chat_models/bedrock_converse.py:699\u001b[39m, in \u001b[36mChatBedrockConverse._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    697\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    698\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUsing Bedrock Converse API to generate response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbedrock_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse from Bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    703\u001b[39m response_message = _parse_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/custom-file-systems/efs/fs-0252e317d4af1dc34_fsap-0a708b50be80889d5/CLONED_REPOS/LLM-World/llmenv/lib/python3.12/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the Converse operation: Invocation of model ID anthropic.claude-sonnet-4-20250514-v1:0 with on-demand throughput isn’t supported. Retry your request with the ID or ARN of an inference profile that contains this model."
     ]
    }
   ],
   "source": [
    "stat_agent = stat_agent()\n",
    "stat_agent.invoke('Get all the columns from df and calculate the principal components then create a scatter plot of the 2 different principal components')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
