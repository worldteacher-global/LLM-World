{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b433f8b-57ec-4b03-861c-4b574d7a7c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/cloned_repo/LLM-World/.venv/bin/python\n",
      "3.11.14 (main, Dec 17 2025, 21:07:37) [Clang 21.1.4 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff05264-7bf7-4592-97cd-b341e0a968cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  9 16:05:15 2026       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.6     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              59W / 400W |  40025MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              56W / 400W |     12MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-40GB          On  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              62W / 400W |  39006MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-40GB          On  | 00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              53W / 400W |     12MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              63W / 400W |    528MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              56W / 400W |     68MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-40GB          On  | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              59W / 400W |     12MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-40GB          On  | 00000000:BD:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              61W / 400W |   2005MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d760b337-80c7-49cd-b6c5-27cd185d09a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/cloned_repo/LLM-World/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import os\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff262ff5-1458-4db6-beef-bc72c34cc184",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff246fa1-a140-4b41-a195-09e65c1345ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/cloned_repo/LLM-World/Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b73f422-9875-46a0-80d8-a296ec55cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/cloned_repo/LLM-World/Files/training_set.jsonl\n",
      "/app/cloned_repo/LLM-World/Files/validation_set.jsonl\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "trn_data = %pwd\n",
    "trn_data = trn_data.replace('Notebooks','Files/training_set.jsonl')\n",
    "val_data = trn_data.replace('training_set','validation_set')\n",
    "print(trn_data)      \n",
    "print(val_data)      \n",
    "print(os.path.exists(trn_data))\n",
    "print(os.path.exists(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b973ca8f-5aa0-4e53-aa54-8e8418529924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 409\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to huggingface dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files={\n",
    "    \"train\":trn_data,\n",
    "    \"valid\":val_data\n",
    "})\n",
    "data\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f4ee86-8a3c-4030-9845-af67d370c55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [[{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user', 'content': 'What is a vector space in linear algebra?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'A vector space is a collection of vectors where you can add them together and multiply them by scalars, following specific rules.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user', 'content': 'Can you explain eigenvalues in simple terms?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Eigenvalues are special numbers that show how a matrix stretches or shrinks vectors along certain directions.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'What is the difference between variance and standard deviation?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Variance measures the average squared deviation from the mean, while standard deviation is the square root of variance, making it easier to interpret in the same units as the data.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'What does it mean if two events are independent in probability?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'It means the occurrence of one event does not affect the probability of the other happening.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'How do you know if two vectors are orthogonal?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Two vectors are orthogonal if their dot product equals zero.'}]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae11543-568e-4c31-842d-deb7a6c72755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [[{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'What is the difference between matrix multiplication and element-wise multiplication?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Matrix multiplication involves dot products between rows and columns, while element-wise multiplication multiplies corresponding entries directly.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user', 'content': 'What is an orthogonal matrix?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'An orthogonal matrix is a square matrix whose rows and columns are orthonormal vectors. Its inverse is the same as its transpose.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user', 'content': 'What is covariance in statistics?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Covariance measures how two variables change together. A positive covariance means they increase together, while a negative one means one increases as the other decreases.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'What is the difference between expectation and variance?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Expectation is the average value of a random variable, while variance measures how much the values fluctuate around that expectation.'}],\n",
       "  [{'role': 'system',\n",
       "    'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "   {'role': 'user', 'content': 'What is the Gram-Schmidt process?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The Gram-Schmidt process takes a set of vectors and produces an orthogonal (or orthonormal) set spanning the same space.'}]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['valid'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb21f64-a56b-4960-8201-6614668bdb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       " {'role': 'user', 'content': 'What is a vector space in linear algebra?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'A vector space is a collection of vectors where you can add them together and multiply them by scalars, following specific rules.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa6f10-b78a-4840-b83c-678668a28635",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de438abe-2c15-41ab-aef1-87baaef5a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/ibm-granite/granite-4.0-h-1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770c6701-f6c9-4a11-b46d-2e1a49738bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6a8afd-8b04-445f-b030-b8131954cc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/app/cloned_repo/LLM-World/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd54a8aa-4aa5-4f8e-a804-85d07f2ce7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "login(token=os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c09237-0fba-4259-a787-70245a45d555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/cloned_repo/LLM-World/Files/sm_output'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = %pwd\n",
    "outp_dir = file_dir.replace('Notebooks','Files/sm_output')\n",
    "outp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5febb6c-4a93-4b78-b117-c2c9d9b7ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dbe61ac-27ef-4e7e-9a8b-dec03e6bef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
     ]
    }
   ],
   "source": [
    "model_id = \"ibm-granite/granite-4.0-h-1b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id) # Load Tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id) # Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66c3914-306d-46ea-b9fd-895f4149d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization (dict -> str) for ability for model to read\n",
    "def serialize_message(input_example):\n",
    "    chat_str = \"\"\n",
    "    for message in input_example['messages']:\n",
    "        role = message['role']\n",
    "        content = message['content']\n",
    "        if role == \"system\":\n",
    "            chat_str += f\"System: {content}\\n\"\n",
    "        elif role == \"user\":\n",
    "            chat_str += f\"User: {content}\\n\"\n",
    "        elif role == \"assistant\":\n",
    "            chat_str += f\"Assistant: {content}\\n\"\n",
    "    input_example[\"text\"] = chat_str\n",
    "    return input_example\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc7f639-1ac5-4498-8e23-7192ab00968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the data\n",
    "def tokenize_text(example):\n",
    "    return tokenizer(\n",
    "        example['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb59195f-4ca3-4d48-8721-8b5385eaad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages', 'text'],\n",
       "        num_rows: 409\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['messages', 'text'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(serialize_message)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51981500-db2a-4fa6-a58b-7b1771a4e1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "  {'role': 'user', 'content': 'What is a vector space in linear algebra?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'A vector space is a collection of vectors where you can add them together and multiply them by scalars, following specific rules.'}],\n",
       " 'text': 'System: You are a mathematician who is specialized in linear algebra and also statistics.\\nUser: What is a vector space in linear algebra?\\nAssistant: A vector space is a collection of vectors where you can add them together and multiply them by scalars, following specific rules.\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a58f60eb-cbc6-446c-a6ef-896865d9f405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 409\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['messages', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(tokenize_text,batched=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1989975b-1bf7-4e5e-ad3e-9304c4303d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are a mathematician who is specialized in linear algebra and also statistics.'},\n",
       "  {'role': 'user', 'content': 'What is a vector space in linear algebra?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'A vector space is a collection of vectors where you can add them together and multiply them by scalars, following specific rules.'}],\n",
       " 'text': 'System: You are a mathematician who is specialized in linear algebra and also statistics.\\nUser: What is a vector space in linear algebra?\\nAssistant: A vector space is a collection of vectors where you can add them together and multiply them by scalars, following specific rules.\\n',\n",
       " 'input_ids': [100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  100256,\n",
       "  2374,\n",
       "  25,\n",
       "  1472,\n",
       "  527,\n",
       "  264,\n",
       "  21651,\n",
       "  1122,\n",
       "  889,\n",
       "  374,\n",
       "  28175,\n",
       "  304,\n",
       "  13790,\n",
       "  47976,\n",
       "  323,\n",
       "  1101,\n",
       "  13443,\n",
       "  627,\n",
       "  1502,\n",
       "  25,\n",
       "  3639,\n",
       "  374,\n",
       "  264,\n",
       "  4724,\n",
       "  3634,\n",
       "  304,\n",
       "  13790,\n",
       "  47976,\n",
       "  5380,\n",
       "  72803,\n",
       "  25,\n",
       "  362,\n",
       "  4724,\n",
       "  3634,\n",
       "  374,\n",
       "  264,\n",
       "  4526,\n",
       "  315,\n",
       "  23728,\n",
       "  1405,\n",
       "  499,\n",
       "  649,\n",
       "  923,\n",
       "  1124,\n",
       "  3871,\n",
       "  323,\n",
       "  31370,\n",
       "  1124,\n",
       "  555,\n",
       "  24964,\n",
       "  1590,\n",
       "  11,\n",
       "  2768,\n",
       "  3230,\n",
       "  5718,\n",
       "  627],\n",
       " 'attention_mask': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "738e4510-8426-479a-86ee-4dddad75b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/cloned_repo/LLM-World/.venv/lib/python3.11/site-packages/transformers/training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# HugingFace Trainer (Basic setup)\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=outp_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    # bf16=True,\n",
    "    no_cuda=True, # dont use gpu when setting up variables If not using LoRA\n",
    "    # use_cpu=True, # dont use gpu when setting up variables If not using LoRA\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    hub_model_id=None,\n",
    "    hub_token=None\n",
    ")\n",
    "\n",
    "# better for training 1B+ OOM error possible without\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\",\"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model,lora_config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=data['train'],\n",
    "    eval_dataset=data['valid'],\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "245e8b32-ef4e-452b-9ba8-74317ddba38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/cloned_repo/LLM-World/Files/sm_artifacts'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = file_dir.replace('Notebooks','Files/sm_artifacts')\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebb925-eaae-4a60-b003-6adb883fd108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/app/cloned_repo/LLM-World/Notebooks/wandb/offline-run-20260109_160553-9kl2ag7y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, mcp] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Trackio project initialized: huggingface\n",
      "* Trackio metrics will be synced to Hugging Face Dataset: marfok/trackio-dataset\n",
      "* Creating new space: https://huggingface.co/spaces/marfok/trackio\n",
      "* View dashboard by going to: https://marfok-trackio.hf.space/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://marfok-trackio.hf.space/\" width=\"100%\" height=\"1000px\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Created new run: marfok-1767974757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GraniteMoeHybrid requires an initialized `HybridMambaAttentionDynamicCache` to return a cache. Because one was not provided, no cache will be returned.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(save_dir)\n",
    "trainer.tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0a3487-80c4-4dd3-bf1d-223d89531fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31577ccc-f3c6-433c-807f-5ef980787fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d764da-62fe-41b8-912d-e08a463d012c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
