{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72b0277-2e44-4572-9ca8-eda2c9de9e4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sample training on 2 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda48f25-431e-4962-beac-f150df382390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized batch: \n",
      " {'input_ids': tensor([[ 101, 2092, 7592, 2045, 1010, 2129, 1005, 1055, 1996, 4633, 1029,  102],\n",
      "        [ 101, 1045, 2064, 1005, 1056, 3524, 2005, 1996, 5353,  999,  102,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "\n",
      "Batch with labels: \n",
      " {'input_ids': tensor([[ 101, 2092, 7592, 2045, 1010, 2129, 1005, 1055, 1996, 4633, 1029,  102],\n",
      "        [ 101, 1045, 2064, 1005, 1056, 3524, 2005, 1996, 5353,  999,  102,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]), 'labels': tensor([1, 1])}\n",
      "\n",
      " AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: True\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "\n",
      " Training loss: \n",
      " tensor(0.4401, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sequence = [\n",
    "    \"Well hello there, how's the weather?\",\n",
    "    \"I can't wait for the weekend!\"\n",
    "]\n",
    "\n",
    "batch = tokenizer(sequence, padding=True, truncation=True, return_tensors='pt')\n",
    "print('Tokenized batch: \\n',batch)\n",
    "\n",
    "## Trainng\n",
    "\n",
    "batch[\"labels\"] = torch.tensor([1,1])\n",
    "print('\\nBatch with labels: \\n',batch)\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "print('\\n',optimizer)\n",
    "\n",
    "loss = model(**batch).loss\n",
    "print(\"\\n Training loss: \\n\", loss)\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537d071-8cfa-47cd-9325-9efd2860b211",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60a1136-aecf-4984-b371-f6ab4cb2427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#GLUE Benchmark (10 different classification tasks) Microsoft Research Paraphrase Corpus\n",
    "\n",
    "data = load_dataset(\"glue\", \"mrpc\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52dd6c6-b02b-4bcb-bb81-b69a3fc57b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data['train']\n",
    "print(train_set[0])\n",
    "\n",
    "## get label mapping\n",
    "\n",
    "train_set.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5dbfe-bb17-4f59-924b-ef9e00c29e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess and turn the text into numnbers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inp = tok(train_set[0]['sentence1'],train_set[0]['sentence2'])\n",
    "print('tokenized input: \\n',inp)\n",
    "\n",
    "print('\\ndecoded tokens: \\n',tok.convert_ids_to_tokens(inp.input_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec9f14e-0089-400c-8569-ea31f77b8298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=103, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## on the entier dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tok(\n",
    "    data['train']['sentence1'][:],\n",
    "    data['train']['sentence2'][:], padding=True, truncation=True)\n",
    "inputs[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351389cb-e785-408d-b380-a563519a89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## padding left out, because padding every sentence can be inefficiant\n",
    "def tokenize_fn(example):\n",
    "    return tok(example['sentence1'], example['sentence2'], truncation=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce7d57c-bb4b-449e-b689-a996652f6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speeds tokenization ###########\n",
    "tok_data = data.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685c1486-c803-4323-8c7d-de48d3f1a3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d31f2c-e103-402e-8cad-0232783552fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data['train']['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d140a0-68e1-47ce-b6f9-e7675ccd731e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "647ec113-5fa3-4c0e-880d-d73e177485a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf9bab-c8c7-4e49-b86a-83f69c3e5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collate function: responsible for putting together samples inside a batch, passed when building a DataLoader.\n",
    "## define a collate fn that will apply the correct amount of padding for the items in a dataset we want batched together\n",
    "## define a collate function that will applky the correct amount of padding to the idems of a batch\n",
    "\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10907f7e-5cd6-435b-b308-5890dcaac19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 59, 47, 67, 59, 50, 62, 32]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get samples we would like to batch ignore string columns\n",
    "samples = tok_data['train'][:8]\n",
    "samples = {k:v for k,v in samples.items() if k not in ['idx','sentence1','sentence2']}\n",
    "\n",
    "[len(x) for x in samples['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74b9a267-7cd0-40f7-b817-36146c2899f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2572,  3217,  5831,  5496,  2010,  2567,  1010,  3183,  2002,\n",
      "          2170,  1000,  1996,  7409,  1000,  1010,  1997,  9969,  4487, 23809,\n",
      "          3436,  2010,  3350,  1012,   102,  7727,  2000,  2032,  2004,  2069,\n",
      "          1000,  1996,  7409,  1000,  1010,  2572,  3217,  5831,  5496,  2010,\n",
      "          2567,  1997,  9969,  4487, 23809,  3436,  2010,  3350,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9805,  3540, 11514,  2050,  3079, 11282,  2243,  1005,  1055,\n",
      "          2077,  4855,  1996,  4677,  2000,  3647,  4576,  1999,  2687,  2005,\n",
      "          1002,  1016,  1012,  1019,  4551,  1012,   102,  9805,  3540, 11514,\n",
      "          2050,  4149, 11282,  2243,  1005,  1055,  1999,  2786,  2005,  1002,\n",
      "          6353,  2509,  2454,  1998,  2853,  2009,  2000,  3647,  4576,  2005,\n",
      "          1002,  1015,  1012,  1022,  4551,  1999,  2687,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2018,  2405,  2019, 15147,  2006,  1996,  4274,  2006,\n",
      "          2238,  2184,  1010,  5378,  1996,  6636,  2005,  5096,  1010,  2002,\n",
      "          2794,  1012,   102,  2006,  2238,  2184,  1010,  1996,  2911,  1005,\n",
      "          1055,  5608,  2018,  2405,  2019, 15147,  2006,  1996,  4274,  1010,\n",
      "          5378,  1996, 14792,  2005,  5096,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2105,  6021, 19481, 13938,  2102,  1010, 21628,  6661,  2020,\n",
      "          2039,  2539, 16653,  1010,  2030,  1018,  1012,  1018,  1003,  1010,\n",
      "          2012,  1037,  1002,  1018,  1012,  5179,  1010,  2383,  3041,  2275,\n",
      "          1037,  2501,  2152,  1997,  1037,  1002,  1018,  1012,  5401,  1012,\n",
      "           102, 21628,  6661,  5598,  2322, 16653,  1010,  2030,  1018,  1012,\n",
      "          1020,  1003,  1010,  2000,  2275,  1037,  2501,  5494,  2152,  2012,\n",
      "          1037,  1002,  1018,  1012,  5401,  1012,   102],\n",
      "        [  101,  1996,  4518,  3123,  1002,  1016,  1012,  2340,  1010,  2030,\n",
      "          2055,  2340,  3867,  1010,  2000,  2485,  5958,  2012,  1002,  2538,\n",
      "          1012,  4868,  2006,  1996,  2047,  2259,  4518,  3863,  1012,   102,\n",
      "         18720,  1004,  1041, 13058,  1012,  6661,  5598,  1002,  1015,  1012,\n",
      "          6191,  2030,  1022,  3867,  2000,  1002,  2538,  1012,  6021,  2006,\n",
      "          1996,  2047,  2259,  4518,  3863,  2006,  5958,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6599,  1999,  1996,  2034,  4284,  1997,  1996,  2095,  3333,\n",
      "          2321,  3867,  2013,  1996,  2168,  2558,  1037,  2095,  3041,  1012,\n",
      "           102,  2007,  1996,  9446,  5689,  2058,  5954,  1005,  1055,  2194,\n",
      "          1010,  6599,  1996,  2034,  4284,  1997,  1996,  2095,  3333,  2321,\n",
      "          3867,  2013,  1996,  2168,  2558,  1037,  2095,  3041,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 17235,  2850,  4160,  2018,  1037,  4882,  5114,  1997,\n",
      "          2459,  1012,  2676,  1010,  2030,  1015,  1012,  1016,  3867,  1010,\n",
      "          5494,  2012,  1015,  1010, 19611,  1012,  2321,  2006,  5958,  1012,\n",
      "           102,  1996,  6627,  1011, 17958, 17235,  2850,  4160, 12490,  1012,\n",
      "         11814,  2594, 24356,  2382,  1012,  4805,  2685,  1010,  2030,  1016,\n",
      "          1012,  5840,  3867,  1010,  2000,  1015,  1010, 19611,  1012,  2321,\n",
      "          1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4966,  1011, 10507,  2050,  2059, 12068,  2000,  1996,\n",
      "          2110,  4259,  2457,  1012,   102,  1996,  4966, 10507,  2050, 12068,\n",
      "          2008,  3247,  2000,  1996,  1057,  1012,  1055,  1012,  4259,  2457,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 0, 1, 0, 1, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "## check to confirm padding is ocurring correcly\n",
    "\n",
    "collated_sample = data_collator(samples)\n",
    "print(collated_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b64f68a-aedb-4165-a37d-a060c26ed3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 67]),\n",
       " 'token_type_ids': torch.Size([8, 67]),\n",
       " 'attention_mask': torch.Size([8, 67]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v.shape for k,v in collated_sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088bb0c-ed13-4c56-91a8-c70614a08176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca8ad266-fbd9-451a-bbc1-27a4a5c50d43",
   "metadata": {},
   "source": [
    "## Fine-tuning Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d74541-3a66-4195-9f59-e01b1dd6a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TRL_GRADIO_ENABLED\"] = \"0\"      # disables Gradio UI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2197fb45-2334-47cf-9836-2b69a1619296",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trainer class helps fine-tune any pretrained models with modern best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f0bd3c-851a-4ad3-93e9-6504260f1cfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## define a TrainingArguments class to contain all the hyperparameters the Trainer will use for training/evaluation\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# help(TrainingArguments)\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir='misc/files/training_out/',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fcec2b-94c4-4f8d-b7ae-9b5c951cd5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## define the model\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c03f7a-6795-4669-bb2f-4c498bfb8952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ba85d-a097-4369-bb3f-b89488200b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a348e3aa-db24-416e-a446-ec2f5972c677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Trainer doesn't work with docker instance and private network, tries to launch gradio on localhost and fails to connect.\n",
    "from transformers import Trainer, DataCollatorWithPadding, AutoTokenizer\n",
    "\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=train_args,\n",
    "    train_dataset=tok_data['train'],\n",
    "    eval_dataset=tok_data['validation'],\n",
    "    data_collator=data_collator,    \n",
    "    processing_class=tok # specifies the tokenizer to use for processing when included, by default data_collator will be DataCollatorWithPadding and can be left out\n",
    ")\n",
    "\n",
    "# from trl import SFTTrainer\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=classifier,\n",
    "#     args=train_args,\n",
    "#     train_dataset=tok_data['train'],\n",
    "#     eval_dataset=tok_data['validation'],\n",
    "#     data_collator=data_collator,\n",
    "#     processing_class=tok\n",
    "    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56945d00-a0a1-451e-a188-b8370246c39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(SFTTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea32756-af2c-4366-ac35-6eb9a658a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [115/115 00:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=115, training_loss=0.3758869005286175, metrics={'train_runtime': 24.6572, 'train_samples_per_second': 148.76, 'train_steps_per_second': 4.664, 'total_flos': 150071968200960.0, 'train_loss': 0.3758869005286175, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fine-tune the model\n",
    "## No info on how well/badly the model performed\n",
    "## Trainer wasnt provided evaluation flag by setting \"eval_strategy\" to either \"steps\" (evaluate every eval_step) or \"epoch\" (evaluate at the end of ea epoch)\n",
    "##  Trainer wasnt provided a \"compute_metrics()\" function to calculate metrics during selected eval-strategy, otherwise loss would be the only thing printed.\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17d504-239b-4a0d-a090-ab2e0db34423",
   "metadata": {},
   "source": [
    "### compute-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "527cae9a-1a03-432e-8ec6-e0aaa1aeb883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "## function must take an EcalPrediction obj (named tuple w/ a predictions field and a label_ids field) and return a dictionary mapping strings to floats (string=names of metrics returned, floats=values)\n",
    "\n",
    "sample_prediction = trainer.predict(tok_data['validation'])\n",
    "print(sample_prediction.predictions.shape, sample_prediction.label_ids.shape) #LOGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cf4033-4916-425b-bc0b-b7ab5ea01e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.37257859110832214, 'test_runtime': 0.7771, 'test_samples_per_second': 525.024, 'test_steps_per_second': 9.008}\n"
     ]
    }
   ],
   "source": [
    "print(sample_prediction.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91aa913e-8e67-4d34-95d9-a54959bf9b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.313618  ,  2.3366494 ],\n",
       "       [ 0.81547284, -0.8704968 ],\n",
       "       [ 0.7014161 , -0.75827986],\n",
       "       [-1.4260672 ,  1.4813273 ],\n",
       "       [ 0.72665334, -0.8391645 ],\n",
       "       [-1.5905647 ,  1.6342868 ],\n",
       "       [-1.6954768 ,  1.7934313 ],\n",
       "       [-2.0704958 ,  2.1199925 ],\n",
       "       [-2.1379464 ,  2.1585248 ],\n",
       "       [-2.4118977 ,  2.3258774 ],\n",
       "       [-2.2651725 ,  2.358853  ],\n",
       "       [ 0.60039145, -0.7614914 ],\n",
       "       [ 1.0158762 , -0.99282056],\n",
       "       [-2.1160028 ,  2.1457396 ],\n",
       "       [-2.4138045 ,  2.3346686 ],\n",
       "       [-1.2120703 ,  1.2329226 ],\n",
       "       [-2.3607144 ,  2.3910458 ],\n",
       "       [ 0.0327654 , -0.21085873],\n",
       "       [-2.3052642 ,  2.4219184 ],\n",
       "       [ 0.7642257 , -0.7667096 ],\n",
       "       [ 0.9869936 , -1.0831897 ],\n",
       "       [-0.21998173,  0.07506118],\n",
       "       [ 0.2530248 , -0.3443814 ],\n",
       "       [-2.2821505 ,  2.227227  ],\n",
       "       [-2.0993223 ,  2.1675234 ],\n",
       "       [-0.29222855,  0.07752119],\n",
       "       [-0.28678158,  0.20813818],\n",
       "       [-2.2870302 ,  2.275493  ],\n",
       "       [-1.1816629 ,  1.1178867 ],\n",
       "       [-2.0200374 ,  2.023765  ],\n",
       "       [-0.05179864, -0.12945434],\n",
       "       [-2.3151975 ,  2.261805  ],\n",
       "       [-0.9583802 ,  0.9288234 ],\n",
       "       [-0.42062986,  0.31923515],\n",
       "       [-2.364702  ,  2.2532015 ],\n",
       "       [-1.714201  ,  1.7029651 ],\n",
       "       [ 0.3982055 , -0.5192362 ],\n",
       "       [ 0.6639114 , -0.7811218 ],\n",
       "       [-1.4962096 ,  1.4871694 ],\n",
       "       [-2.247554  ,  2.1656046 ],\n",
       "       [ 0.8786101 , -0.89107865],\n",
       "       [-2.0151546 ,  2.2289565 ],\n",
       "       [-0.776491  ,  0.6419863 ],\n",
       "       [ 0.69219744, -0.6911428 ],\n",
       "       [-0.37512153,  0.3429072 ],\n",
       "       [-2.3692336 ,  2.3682144 ],\n",
       "       [-2.166267  ,  2.2358525 ],\n",
       "       [ 0.70021933, -0.6918912 ],\n",
       "       [-2.3117874 ,  2.3020382 ],\n",
       "       [-1.9701838 ,  2.0634284 ],\n",
       "       [-1.7103469 ,  1.6556598 ],\n",
       "       [-2.0403447 ,  2.0523455 ],\n",
       "       [-2.1108096 ,  2.1205454 ],\n",
       "       [-2.3393724 ,  2.3484468 ],\n",
       "       [-2.0009198 ,  2.0075786 ],\n",
       "       [-2.0443766 ,  2.1045756 ],\n",
       "       [-0.4942052 ,  0.53023607],\n",
       "       [-2.308493  ,  2.386231  ],\n",
       "       [-2.3415961 ,  2.1959317 ],\n",
       "       [-1.5141559 ,  1.578136  ],\n",
       "       [-0.9848443 ,  0.92303   ],\n",
       "       [ 0.24343227, -0.34814873],\n",
       "       [-2.3673499 ,  2.3657134 ],\n",
       "       [-1.9292524 ,  1.9134678 ],\n",
       "       [-1.9829749 ,  1.9745564 ],\n",
       "       [ 0.68527603, -0.7028816 ],\n",
       "       [-2.333033  ,  2.4161167 ],\n",
       "       [-2.259536  ,  2.1746495 ],\n",
       "       [-0.11012989, -0.05914943],\n",
       "       [-2.2987125 ,  2.3643098 ],\n",
       "       [-2.2175255 ,  2.14716   ],\n",
       "       [-0.5511867 ,  0.57142043],\n",
       "       [-2.2757685 ,  2.39655   ],\n",
       "       [-2.1321528 ,  2.148477  ],\n",
       "       [-1.6283466 ,  1.6241652 ],\n",
       "       [-1.8711158 ,  2.0231254 ],\n",
       "       [-2.076612  ,  2.2307167 ],\n",
       "       [-2.3413663 ,  2.3835392 ],\n",
       "       [-2.0385664 ,  2.1350574 ],\n",
       "       [-2.3126678 ,  2.3603458 ],\n",
       "       [-0.1652794 ,  0.16064069],\n",
       "       [-2.1514742 ,  2.2418268 ],\n",
       "       [-2.2692323 ,  2.2897027 ],\n",
       "       [ 0.42860886, -0.51358837],\n",
       "       [-2.1386464 ,  2.120302  ],\n",
       "       [ 0.28937307, -0.47625172],\n",
       "       [-1.5587254 ,  1.5719362 ],\n",
       "       [-0.76848334,  0.79889977],\n",
       "       [-2.342445  ,  2.3945887 ],\n",
       "       [-2.3480635 ,  2.35188   ],\n",
       "       [-0.18576172,  0.11321998],\n",
       "       [-2.3218591 ,  2.3850334 ],\n",
       "       [-2.2161014 ,  2.2150526 ],\n",
       "       [-1.9602171 ,  1.9582793 ],\n",
       "       [-2.3506682 ,  2.3938363 ],\n",
       "       [-2.260053  ,  2.2903154 ],\n",
       "       [ 0.47590283, -0.5832625 ],\n",
       "       [-2.038504  ,  2.0709653 ],\n",
       "       [-1.6010346 ,  1.615185  ],\n",
       "       [-2.1860669 ,  2.1622424 ],\n",
       "       [-1.469336  ,  1.4872857 ],\n",
       "       [ 0.19661333, -0.35858688],\n",
       "       [-1.5422184 ,  1.5724263 ],\n",
       "       [-2.2351189 ,  2.2064114 ],\n",
       "       [ 0.18938951, -0.31545907],\n",
       "       [-2.249442  ,  2.2830615 ],\n",
       "       [-1.1858757 ,  1.2452781 ],\n",
       "       [ 1.0311372 , -1.0054264 ],\n",
       "       [ 0.86174595, -0.84841067],\n",
       "       [-2.2093804 ,  2.1798959 ],\n",
       "       [-1.0759827 ,  1.1211898 ],\n",
       "       [-1.8133626 ,  1.8326445 ],\n",
       "       [-2.0330014 ,  1.9994644 ],\n",
       "       [-2.3355517 ,  2.4171813 ],\n",
       "       [-1.102779  ,  1.1716349 ],\n",
       "       [ 0.32386312, -0.49593726],\n",
       "       [-2.2707174 ,  2.2447715 ],\n",
       "       [-2.0888531 ,  2.0782154 ],\n",
       "       [-2.1245954 ,  2.0502608 ],\n",
       "       [-2.2855272 ,  2.2674832 ],\n",
       "       [-2.2537282 ,  2.1769767 ],\n",
       "       [-0.43496707,  0.48146272],\n",
       "       [ 1.0806562 , -1.055176  ],\n",
       "       [-2.234796  ,  2.280922  ],\n",
       "       [-2.403644  ,  2.3796377 ],\n",
       "       [-2.1827867 ,  2.277315  ],\n",
       "       [-2.1883562 ,  2.1751096 ],\n",
       "       [ 0.7571463 , -0.82819194],\n",
       "       [-2.3400779 ,  2.4049578 ],\n",
       "       [-2.1535337 ,  2.1256242 ],\n",
       "       [-1.9766643 ,  1.9853957 ],\n",
       "       [-0.11893784, -0.07141873],\n",
       "       [-2.0857506 ,  2.1152055 ],\n",
       "       [-0.03862765, -0.08707698],\n",
       "       [-1.260079  ,  1.3005335 ],\n",
       "       [-1.9676734 ,  1.9548448 ],\n",
       "       [ 0.03829432, -0.18501763],\n",
       "       [ 0.9606813 , -0.9766741 ],\n",
       "       [-2.3975112 ,  2.371222  ],\n",
       "       [-2.134306  ,  2.095937  ],\n",
       "       [-2.325532  ,  2.3518727 ],\n",
       "       [ 0.4920801 , -0.61397356],\n",
       "       [ 0.8664914 , -1.0435877 ],\n",
       "       [-2.106765  ,  2.0372887 ],\n",
       "       [ 0.9192005 , -0.932969  ],\n",
       "       [-1.0283972 ,  1.0099442 ],\n",
       "       [-2.2997577 ,  2.3322814 ],\n",
       "       [-0.5656445 ,  0.44481915],\n",
       "       [ 0.45981288, -0.50561035],\n",
       "       [-1.8707236 ,  1.9285558 ],\n",
       "       [ 0.80540854, -0.8954974 ],\n",
       "       [-1.4759116 ,  1.4603024 ],\n",
       "       [-1.5361145 ,  1.552009  ],\n",
       "       [-2.2903123 ,  2.4198577 ],\n",
       "       [-0.784145  ,  0.7854328 ],\n",
       "       [-2.1162968 ,  2.1173096 ],\n",
       "       [-2.262322  ,  2.21301   ],\n",
       "       [-0.40028378,  0.59475625],\n",
       "       [ 0.33819306, -0.48547328],\n",
       "       [-1.1763077 ,  1.3015217 ],\n",
       "       [-1.6503173 ,  1.6966102 ],\n",
       "       [-2.305722  ,  2.2499564 ],\n",
       "       [-2.3749123 ,  2.41465   ],\n",
       "       [-2.4065652 ,  2.3609633 ],\n",
       "       [-2.0528464 ,  2.078269  ],\n",
       "       [-2.0185952 ,  1.9373548 ],\n",
       "       [-1.5301144 ,  1.5246855 ],\n",
       "       [ 0.32827228, -0.44876763],\n",
       "       [-2.0439084 ,  2.0816474 ],\n",
       "       [ 0.25378984, -0.43757427],\n",
       "       [ 0.41342738, -0.5747699 ],\n",
       "       [ 0.10421328, -0.28198594],\n",
       "       [-0.40306428,  0.27690277],\n",
       "       [-1.9459926 ,  1.9663886 ],\n",
       "       [-0.5199775 ,  0.38344258],\n",
       "       [-1.7550209 ,  1.7944188 ],\n",
       "       [-2.2504325 ,  2.2603526 ],\n",
       "       [ 0.5555307 , -0.5421983 ],\n",
       "       [-2.188338  ,  2.200712  ],\n",
       "       [-2.3055222 ,  2.407137  ],\n",
       "       [-0.07000045, -0.15675785],\n",
       "       [-1.189691  ,  1.0853509 ],\n",
       "       [-2.357618  ,  2.3085496 ],\n",
       "       [-2.3992884 ,  2.3911214 ],\n",
       "       [-0.13180552, -0.06984361],\n",
       "       [-2.16225   ,  2.071345  ],\n",
       "       [ 0.38832903, -0.5297866 ],\n",
       "       [-0.01340308, -0.19034874],\n",
       "       [ 0.78363   , -0.85858923],\n",
       "       [-2.1160038 ,  2.1325498 ],\n",
       "       [-2.2333753 ,  2.3341527 ],\n",
       "       [ 0.94952154, -0.9993218 ],\n",
       "       [ 0.10684019, -0.35535365],\n",
       "       [-2.3161085 ,  2.3629255 ],\n",
       "       [-0.8443139 ,  0.79493934],\n",
       "       [-1.9531502 ,  1.9999502 ],\n",
       "       [-2.310836  ,  2.3667982 ],\n",
       "       [-0.19096433,  0.06204295],\n",
       "       [-1.9704311 ,  1.9684261 ],\n",
       "       [-1.9399288 ,  1.9672757 ],\n",
       "       [-2.066232  ,  2.0596223 ],\n",
       "       [-1.9493074 ,  1.9366075 ],\n",
       "       [-0.12722479,  0.11159224],\n",
       "       [-2.0594702 ,  2.0909297 ],\n",
       "       [-1.9697157 ,  1.9978495 ],\n",
       "       [-0.22948062,  0.09906803],\n",
       "       [-2.26051   ,  2.361604  ],\n",
       "       [-1.8251879 ,  1.8202136 ],\n",
       "       [ 0.09681824, -0.24505256],\n",
       "       [-0.14595503,  0.05061081],\n",
       "       [ 0.03315531, -0.19920437],\n",
       "       [-2.3569987 ,  2.4237058 ],\n",
       "       [-1.3150567 ,  1.387053  ],\n",
       "       [ 0.7148771 , -0.8279976 ],\n",
       "       [-2.290045  ,  2.2465472 ],\n",
       "       [-2.340311  ,  2.300183  ],\n",
       "       [-1.3915211 ,  1.3971155 ],\n",
       "       [-2.1215024 ,  2.1692088 ],\n",
       "       [ 0.68332577, -0.77251804],\n",
       "       [-2.2267604 ,  2.3143137 ],\n",
       "       [-0.33133048,  0.18785068],\n",
       "       [-0.9835298 ,  0.82892984],\n",
       "       [-2.1864264 ,  2.1978815 ],\n",
       "       [ 1.0576481 , -0.92894685],\n",
       "       [-2.3430603 ,  2.3022904 ],\n",
       "       [-2.361214  ,  2.290649  ],\n",
       "       [-2.308009  ,  2.2767663 ],\n",
       "       [-1.7938035 ,  1.8417583 ],\n",
       "       [-2.0291026 ,  2.0916345 ],\n",
       "       [-2.1750972 ,  2.2163212 ],\n",
       "       [-2.3535638 ,  2.3768778 ],\n",
       "       [-2.292238  ,  2.238172  ],\n",
       "       [-0.15479228,  0.0126759 ],\n",
       "       [-0.5410172 ,  0.50977534],\n",
       "       [-0.4182858 ,  0.3121481 ],\n",
       "       [ 0.20604697, -0.29974025],\n",
       "       [-0.97152275,  0.929923  ],\n",
       "       [ 0.34888008, -0.52925205],\n",
       "       [-0.52120703,  0.45096132],\n",
       "       [-0.1961947 ,  0.07466418],\n",
       "       [-1.8692031 ,  1.8182869 ],\n",
       "       [ 0.8845834 , -1.0182874 ],\n",
       "       [-0.37202308,  0.22716795],\n",
       "       [-1.5502336 ,  1.5807703 ],\n",
       "       [-2.2550719 ,  2.230373  ],\n",
       "       [-1.9115636 ,  1.9985228 ],\n",
       "       [-1.9502766 ,  1.8998029 ],\n",
       "       [-1.1588032 ,  1.1477618 ],\n",
       "       [-2.2196734 ,  2.34739   ],\n",
       "       [-1.6187474 ,  1.6935029 ],\n",
       "       [-2.0022626 ,  2.0156295 ],\n",
       "       [-1.0889105 ,  0.9735045 ],\n",
       "       [ 0.0230157 , -0.17885573],\n",
       "       [-0.30992937,  0.11979382],\n",
       "       [ 0.92138857, -0.8851436 ],\n",
       "       [ 1.1335666 , -1.0476036 ],\n",
       "       [-2.2117047 ,  2.3017426 ],\n",
       "       [-2.074108  ,  2.2831101 ],\n",
       "       [-2.0006073 ,  1.9765451 ],\n",
       "       [-0.09563575, -0.02671062],\n",
       "       [-1.8491305 ,  1.9384112 ],\n",
       "       [-0.986484  ,  0.8720013 ],\n",
       "       [-2.2791917 ,  2.3846464 ],\n",
       "       [-2.1164708 ,  2.112015  ],\n",
       "       [-0.4568616 ,  0.41056857],\n",
       "       [-0.99736804,  0.97856855],\n",
       "       [ 0.06114803, -0.16153911],\n",
       "       [ 0.25957212, -0.36266947],\n",
       "       [ 0.59664667, -0.77269703],\n",
       "       [-2.0155838 ,  1.917481  ],\n",
       "       [ 0.46448243, -0.5934967 ],\n",
       "       [-2.373408  ,  2.319093  ],\n",
       "       [-2.2835844 ,  2.3439102 ],\n",
       "       [-2.1706767 ,  2.1081073 ],\n",
       "       [-2.3153002 ,  2.3335893 ],\n",
       "       [-1.8584905 ,  1.9242083 ],\n",
       "       [-2.015663  ,  2.0212772 ],\n",
       "       [ 0.06541866, -0.13457097],\n",
       "       [-2.1244812 ,  2.14842   ],\n",
       "       [ 0.8054109 , -0.8867175 ],\n",
       "       [-0.6445223 ,  0.5441669 ],\n",
       "       [-1.685202  ,  1.7099875 ],\n",
       "       [-0.6289613 ,  0.5043525 ],\n",
       "       [ 1.0825907 , -1.1160555 ],\n",
       "       [-0.25301343,  0.16601433],\n",
       "       [-2.269665  ,  2.173315  ],\n",
       "       [-2.2607105 ,  2.3945732 ],\n",
       "       [-0.68001956,  0.73124313],\n",
       "       [-2.232063  ,  2.2328951 ],\n",
       "       [ 0.34435537, -0.53800434],\n",
       "       [-1.1289353 ,  1.1884868 ],\n",
       "       [ 0.8848986 , -0.8582537 ],\n",
       "       [-2.45174   ,  2.3518221 ],\n",
       "       [-0.73342115,  0.73233664],\n",
       "       [-1.7414646 ,  1.7681018 ],\n",
       "       [ 0.37672013, -0.53681654],\n",
       "       [ 0.56583226, -0.6674329 ],\n",
       "       [-1.9415826 ,  1.9401889 ],\n",
       "       [-2.3483112 ,  2.418119  ],\n",
       "       [-0.04223766, -0.087685  ],\n",
       "       [-2.2839556 ,  2.3602834 ],\n",
       "       [-2.3378832 ,  2.3154    ],\n",
       "       [-2.2086606 ,  2.251844  ],\n",
       "       [ 0.40942228, -0.5535157 ],\n",
       "       [-1.7791083 ,  1.8002657 ],\n",
       "       [-2.0823295 ,  2.177714  ],\n",
       "       [ 0.79411   , -0.8714275 ],\n",
       "       [-2.362616  ,  2.4160628 ],\n",
       "       [ 1.1114734 , -1.0614008 ],\n",
       "       [-1.2409542 ,  1.2719096 ],\n",
       "       [-2.119436  ,  2.166032  ],\n",
       "       [-2.2901468 ,  2.2531192 ],\n",
       "       [-0.30879298,  0.16230734],\n",
       "       [ 0.6574754 , -0.7044417 ],\n",
       "       [-2.3117476 ,  2.3960478 ],\n",
       "       [ 0.10839722, -0.2767416 ],\n",
       "       [ 0.41440707, -0.5372193 ],\n",
       "       [-2.0496664 ,  2.223687  ],\n",
       "       [ 0.4777763 , -0.52787304],\n",
       "       [ 0.5600524 , -0.5798098 ],\n",
       "       [ 0.43418264, -0.54326165],\n",
       "       [ 1.0734973 , -1.1395456 ],\n",
       "       [ 1.0868281 , -1.1745819 ],\n",
       "       [-0.01352109, -0.07970357],\n",
       "       [ 0.0749092 , -0.2129374 ],\n",
       "       [-2.3890102 ,  2.4006748 ],\n",
       "       [-1.7326022 ,  1.7515354 ],\n",
       "       [-2.3413007 ,  2.407668  ],\n",
       "       [-2.137386  ,  2.2094307 ],\n",
       "       [-0.40094504,  0.19025452],\n",
       "       [-2.283463  ,  2.235841  ],\n",
       "       [-2.3578215 ,  2.3973305 ],\n",
       "       [-0.27266404,  0.09816515],\n",
       "       [-1.9826689 ,  2.0044675 ],\n",
       "       [-2.2057621 ,  2.2375977 ],\n",
       "       [-2.0211997 ,  2.0765634 ],\n",
       "       [-2.1595163 ,  2.18164   ],\n",
       "       [-2.2992265 ,  2.3066888 ],\n",
       "       [-0.45090887,  0.29810718],\n",
       "       [-1.3071945 ,  1.2743877 ],\n",
       "       [-2.2847056 ,  2.3709798 ],\n",
       "       [-2.3939302 ,  2.3668282 ],\n",
       "       [ 0.96529883, -0.93076044],\n",
       "       [ 0.01349213, -0.16873191],\n",
       "       [-2.2884622 ,  2.346971  ],\n",
       "       [-2.3254616 ,  2.4032195 ],\n",
       "       [-2.2836094 ,  2.3074281 ],\n",
       "       [-2.32885   ,  2.3463833 ],\n",
       "       [-1.1625446 ,  1.1952488 ],\n",
       "       [-1.9555547 ,  1.9953955 ],\n",
       "       [ 0.51424164, -0.6785323 ],\n",
       "       [-2.1676857 ,  2.361132  ],\n",
       "       [-0.282105  ,  0.11372066],\n",
       "       [-0.67834663,  0.6069393 ],\n",
       "       [ 0.29164007, -0.48691204],\n",
       "       [ 1.0402141 , -0.97181255],\n",
       "       [-2.0578    ,  2.1052454 ],\n",
       "       [-1.3440573 ,  1.4044572 ],\n",
       "       [-1.941215  ,  2.0019252 ],\n",
       "       [-2.20667   ,  2.1684332 ],\n",
       "       [ 0.6032369 , -0.65302217],\n",
       "       [-1.7410709 ,  1.7777919 ],\n",
       "       [-2.4025338 ,  2.4226012 ],\n",
       "       [ 0.1790342 , -0.3706003 ],\n",
       "       [-2.1866353 ,  2.1320732 ],\n",
       "       [-2.3550231 ,  2.413137  ],\n",
       "       [-2.2577052 ,  2.3827457 ],\n",
       "       [-0.6928691 ,  0.5727799 ],\n",
       "       [ 0.5013092 , -0.57388866],\n",
       "       [-0.21908344,  0.1048475 ],\n",
       "       [-0.10805363, -0.05825273],\n",
       "       [-2.2887282 ,  2.3526196 ],\n",
       "       [-2.279676  ,  2.243357  ],\n",
       "       [-1.7333369 ,  1.8951648 ],\n",
       "       [ 0.58850485, -0.62895226],\n",
       "       [-0.33731383,  0.15478352],\n",
       "       [-1.0564799 ,  0.95407987],\n",
       "       [ 0.31635156, -0.5105653 ],\n",
       "       [-1.3718456 ,  1.3534403 ],\n",
       "       [-2.2938309 ,  2.233859  ],\n",
       "       [-1.7162225 ,  1.6659013 ],\n",
       "       [-2.3784106 ,  2.3685637 ],\n",
       "       [ 0.37838775, -0.5417479 ],\n",
       "       [-2.3348732 ,  2.3888862 ],\n",
       "       [-0.7155106 ,  0.5774836 ],\n",
       "       [-0.6207822 ,  0.4846076 ],\n",
       "       [-1.3110713 ,  1.377855  ],\n",
       "       [ 0.34501174, -0.39492664],\n",
       "       [-2.2926316 ,  2.2560506 ],\n",
       "       [ 0.13117783, -0.27486935],\n",
       "       [-2.3495545 ,  2.3746624 ],\n",
       "       [-1.7189839 ,  1.7772052 ],\n",
       "       [-2.3345652 ,  2.2556694 ],\n",
       "       [-2.3354394 ,  2.3617697 ],\n",
       "       [-1.866198  ,  1.8981074 ],\n",
       "       [-1.9144744 ,  1.9187919 ],\n",
       "       [-2.3735046 ,  2.4032748 ],\n",
       "       [ 0.27081808, -0.30594593],\n",
       "       [ 0.09015857, -0.17238893],\n",
       "       [-2.4090028 ,  2.28821   ],\n",
       "       [ 1.0141506 , -0.9709253 ],\n",
       "       [-2.2558405 ,  2.280749  ],\n",
       "       [-0.86594677,  0.8402752 ],\n",
       "       [ 0.9209056 , -0.9799408 ],\n",
       "       [-0.55495214,  0.58717257],\n",
       "       [-2.4344413 ,  2.3784153 ],\n",
       "       [-0.04752554, -0.00940202],\n",
       "       [-1.8999115 ,  1.9012271 ]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.37257859110832214, 'test_runtime': 0.7771, 'test_samples_per_second': 525.024, 'test_steps_per_second': 9.008})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16119382-07e6-425e-a289-cd9cc2539fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## take the index with the maximum value on the second axis to compate to labels\n",
    "\n",
    "preds = np.argmax(sample_prediction.predictions, axis=-1) #PREDICITON\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38bc0730-030f-4450-9836-f0f4f83363ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3b0f5ef-9bca-4792-aafb-d8a7d830bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8357843137254902, 'f1': 0.8858603066439523}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "## load metrics associated with MRPC dataset\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=sample_prediction.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2b320-0a0e-499a-8b56-84464017f80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0027f988-5839-4e4c-985d-8a14e51e7712",
   "metadata": {},
   "source": [
    "## All together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4937fd5c-3678-444f-beb6-31d78cd36b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TRL_GRADIO_ENABLED\"] = \"0\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312f2015-85bf-4ad2-9898-52fa1203c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Trainer doesn't work with docker instance and private network, tries to launch gradio on localhost and fails to connect.\n",
    "from transformers import Trainer, DataCollatorWithPadding, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "#GLUE Benchmark (10 different classification tasks) Microsoft Research Paraphrase Corpus\n",
    "\n",
    "data = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tok(\n",
    "    data['train']['sentence1'][:],\n",
    "    data['train']['sentence2'][:], padding=True, truncation=True)\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tok(example['sentence1'], example['sentence2'], truncation=True)\n",
    "\n",
    "tok_data = data.map(tokenize_fn, batched=True)\n",
    "\n",
    "def compute_metrics_mrpc(eval_preds):\n",
    "    metric = evaluate.load(\"glue\",\"mrpc\")\n",
    "    logits,labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)\n",
    "    \n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "train_arguments = TrainingArguments(\n",
    "    output_dir='misc/files/training_out/',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=train_arguments,\n",
    "    train_dataset=tok_data['train'],\n",
    "    eval_dataset=tok_data['validation'],\n",
    "    data_collator=data_collator,    \n",
    "    processing_class=tok,\n",
    "    compute_metrics=compute_metrics_mrpc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41449424-71ef-4f6a-a234-f26a961a1d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6493242979049683, 'test_accuracy': 0.6838235294117647, 'test_f1': 0.8122270742358079, 'test_runtime': 1.4099, 'test_samples_per_second': 289.377, 'test_steps_per_second': 4.965}\n"
     ]
    }
   ],
   "source": [
    "logits = trainer.predict(tok_data['validation'])\n",
    "\n",
    "print(logits.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa91178f-e78a-486f-9df6-d6c15003c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### mixed precision trainig\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    'misc/files/training_out/',\n",
    "    eval_strategy='epoch',\n",
    "    fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ab3711-0864-41bd-9aef-6f4de838a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gradient accumulation\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    'misc/files/training_out/',\n",
    "    eval_strategy='epoch',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4) # Effective bastch size = 4*4=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c4c04-7e5b-4cfe-9d23-c79b3b21a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    'misc/files/training_out/',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='cosine'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
