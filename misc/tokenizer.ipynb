{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a791a2d-94b9-4e2e-a393-c89b1705c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce5b218-ac98-4cba-a8f7-f9559179be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[54609,  1078,  6602, 24223,   382,  2827],\n",
       "        [   40,  4128,  1299,   532,  2760, 10664]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'openai/gpt-oss-20b'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "raw_input = [\n",
    "    \"Learning about tokenizers is fun\",\n",
    "    \"I don't like OOM errors\"\n",
    "]\n",
    "\n",
    "inp = tokenizer(raw_input, padding=True, truncation=True, return_tensors='pt')\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6b15bec-fc2f-41f3-b710-48d1272a9016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=6, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c391600-e27d-422c-bc85-21c768808938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [13347, 382, 41482, 3521, 30], 'attention_mask': [1, 1, 1, 1, 1]}\n",
      "what is today's date?\n"
     ]
    }
   ],
   "source": [
    "inp = tokenizer(\"what is today's date?\")\n",
    "print(inp)\n",
    "print(tokenizer.decode(inp['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778507ca-c0a2-477c-b771-d993ab3dd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download pretrained model\n",
    "# *Model (retrieve the hidden states)\n",
    "# *ForCausalLM\n",
    "# *ForMaskedLM\n",
    "# *ForMultipleChoice\n",
    "# *ForQuestionAnswering\n",
    "# *ForSequenceClassification\n",
    "# *ForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5334c0e-976b-4c56-9c2d-f4a53e01156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a32def-caf8-4e0b-9bd1-bfae4cd80ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa48085a78246c990364d35d9b928d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 40 files:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943489e16bbc4893b4dcf5d673166315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_card = 'openai/gpt-oss-20b'\n",
    "\n",
    "model = AutoModel.from_pretrained(model_card, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d143d7-6ce0-4480-8e80-bf3923ce630c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GptOssModel(\n",
       "  (embed_tokens): Embedding(201088, 2880, padding_idx=199999)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x GptOssDecoderLayer(\n",
       "      (self_attn): GptOssAttention(\n",
       "        (q_proj): Linear(in_features=2880, out_features=4096, bias=True)\n",
       "        (k_proj): Linear(in_features=2880, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=2880, out_features=512, bias=True)\n",
       "        (o_proj): Linear(in_features=4096, out_features=2880, bias=True)\n",
       "      )\n",
       "      (mlp): GptOssMLP(\n",
       "        (router): GptOssTopKRouter()\n",
       "        (experts): Mxfp4GptOssExperts()\n",
       "      )\n",
       "      (input_layernorm): GptOssRMSNorm((2880,), eps=1e-05)\n",
       "      (post_attention_layernorm): GptOssRMSNorm((2880,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (norm): GptOssRMSNorm((2880,), eps=1e-05)\n",
       "  (rotary_emb): GptOssRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df34468-120f-4e09-8456-4e449f207fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoeModelOutputWithPast(last_hidden_state=tensor([[[ 1.2188e+00, -4.2500e+00,  4.1250e+00,  ..., -4.0312e+00,\n",
       "           9.1250e+00, -1.8375e+01],\n",
       "         [-5.1875e+00,  2.4219e+00, -1.4062e+00,  ..., -1.5469e+00,\n",
       "           3.3203e-01, -1.9125e+01],\n",
       "         [-8.5156e-01, -1.0703e+00,  3.8125e+00,  ...,  2.5312e+00,\n",
       "           3.7188e+00, -1.9062e+00],\n",
       "         [-1.5625e+00, -1.6406e+00,  3.0469e+00,  ...,  9.9219e-01,\n",
       "           4.8750e+00, -1.1938e+01],\n",
       "         [-8.8750e+00, -2.7148e-01, -8.4375e-01,  ..., -1.8203e+00,\n",
       "           3.0312e+00,  4.0000e+00],\n",
       "         [-5.4688e+00,  3.7305e-01,  3.0273e-01,  ..., -1.3281e+00,\n",
       "          -1.0312e+00, -3.6250e+00]],\n",
       "\n",
       "        [[-7.5625e+00, -3.0312e+00, -9.2578e-01,  ...,  9.6875e-01,\n",
       "          -3.2344e+00, -3.4531e+00],\n",
       "         [ 1.4562e+01,  4.6875e+00, -5.1953e-01,  ..., -2.6719e+00,\n",
       "           2.4531e+00, -1.8281e+00],\n",
       "         [-8.3125e+00,  2.9531e+00,  2.5781e+00,  ..., -4.1250e+00,\n",
       "           1.9609e+00, -1.3625e+01],\n",
       "         [-1.2375e+01,  1.5137e-01,  1.1719e+00,  ..., -8.2812e-01,\n",
       "          -2.8125e-01, -3.2344e+00],\n",
       "         [ 6.2561e-03, -3.9844e+00,  8.1250e+00,  ...,  2.2656e+00,\n",
       "           1.6328e+00, -1.6000e+01],\n",
       "         [-6.6875e+00,  6.1719e-01,  1.8750e-01,  ..., -2.5625e+00,\n",
       "          -1.9609e+00, -7.7734e-01]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<ToCopyBackward0>), past_key_values=DynamicCache(layers=[<transformers.cache_utils.DynamicLayer object at 0x7ff0b0a5e240>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0ac23f0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0ace540>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acefc0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acd9a0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0ace210>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acdf10>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acf470>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acda60>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0accd70>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acdaf0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acf9b0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acf920>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acfbc0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acfcb0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acfef0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acd8b0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acca40>, <transformers.cache_utils.DynamicLayer object at 0x7ff10c59b950>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0ac31d0>, <transformers.cache_utils.DynamicLayer object at 0x7ff10c56d7c0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0ace8a0>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0acea80>, <transformers.cache_utils.DynamicLayer object at 0x7ff0b0ace6f0>]), hidden_states=None, attentions=None, router_logits=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(**inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b183aa6-2011-49b1-8440-260e10487250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2880])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2188e+00, -4.2500e+00,  4.1250e+00,  ..., -4.0312e+00,\n",
       "           9.1250e+00, -1.8375e+01],\n",
       "         [-5.1875e+00,  2.4219e+00, -1.4062e+00,  ..., -1.5469e+00,\n",
       "           3.3203e-01, -1.9125e+01],\n",
       "         [-8.5156e-01, -1.0703e+00,  3.8125e+00,  ...,  2.5312e+00,\n",
       "           3.7188e+00, -1.9062e+00],\n",
       "         [-1.5625e+00, -1.6406e+00,  3.0469e+00,  ...,  9.9219e-01,\n",
       "           4.8750e+00, -1.1938e+01],\n",
       "         [-8.8750e+00, -2.7148e-01, -8.4375e-01,  ..., -1.8203e+00,\n",
       "           3.0312e+00,  4.0000e+00],\n",
       "         [-5.4688e+00,  3.7305e-01,  3.0273e-01,  ..., -1.3281e+00,\n",
       "          -1.0312e+00, -3.6250e+00]],\n",
       "\n",
       "        [[-7.5625e+00, -3.0312e+00, -9.2578e-01,  ...,  9.6875e-01,\n",
       "          -3.2344e+00, -3.4531e+00],\n",
       "         [ 1.4562e+01,  4.6875e+00, -5.1953e-01,  ..., -2.6719e+00,\n",
       "           2.4531e+00, -1.8281e+00],\n",
       "         [-8.3125e+00,  2.9531e+00,  2.5781e+00,  ..., -4.1250e+00,\n",
       "           1.9609e+00, -1.3625e+01],\n",
       "         [-1.2375e+01,  1.5137e-01,  1.1719e+00,  ..., -8.2812e-01,\n",
       "          -2.8125e-01, -3.2344e+00],\n",
       "         [ 6.2561e-03, -3.9844e+00,  8.1250e+00,  ...,  2.2656e+00,\n",
       "           1.6328e+00, -1.6000e+01],\n",
       "         [-6.6875e+00,  6.1719e-01,  1.8750e-01,  ..., -2.5625e+00,\n",
       "          -1.9609e+00, -7.7734e-01]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out.last_hidden_state.shape)\n",
    "out.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1d1d710-c2a6-4cab-bdfb-01b0fe74cea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'past_key_values'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e946842-efec-4b72-bd63-852a8f457a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fe7756-1b92-4010-8870-cf3b7eb5d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4083,  2055, 19204, 17629,  2015,  2003,  4569,   102,     0],\n",
       "        [  101,  1045,  2123,  1005,  1056,  2066,  1051,  5358, 10697,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_card = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_card)\n",
    "\n",
    "raw_input = [\n",
    "    \"Learning about tokenizers is fun\",\n",
    "    \"I don't like OOM errors\"\n",
    "]\n",
    "\n",
    "inp = tok(raw_input, padding=True, truncation=True, return_tensors='pt')\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e2e37db-d667-4853-8215-db5471fc82a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce39980142543c1aa01c63ff4d45a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "out = model(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0f6690-03a9-4cc2-95a7-159d84eb2bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-4.2268,  4.5430],\n",
       "        [ 2.5654, -2.1671]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits (raw unnormalized scores to be converted into probability)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb1c970-8387-4ea7-a8a7-9bed647058ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5533e-04, 9.9984e-01],\n",
       "        [9.9127e-01, 8.7273e-03]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pred = torch.nn.functional.softmax(out.logits, dim=-1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7e9d79-6833-48e5-b9ed-a7983a204688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee1e52-78eb-4718-bf95-5757580a236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First sentence: NEGATIVE: 0.0402, POSITIVE: 0.9598\n",
    "# Second sentence: NEGATIVE: 0.9995, POSITIVE: 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6265d-5524-4fa8-bef6-6c3713dc9527",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be6d11c-acc7-4c92-afbf-ec2afcdf3fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d12709d7704759afe7889c5aaed80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374972d0b08443cfb2fd5aada2fcc00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9999ebb-7f99-44b7-a64b-c79aab75b74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b7f5b4-d572-4253-9d9f-b10967a66acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/misc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bd5af-462a-45fa-9c6e-aaa5129e74b6",
   "metadata": {},
   "source": [
    "## saving model weights and arch config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb68a995-e9bc-4b70-ab2b-3d7747bf2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model weights and architecture config\n",
    "\n",
    "model.save_pretrained('/app/misc/model_card/model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec67b5e-8613-45a7-aa21-2991220d106c",
   "metadata": {},
   "source": [
    "## Multiple sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd48b185-49bd-4dc4-bd6f-a843ba9ff29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87678b21-5ab4-47b7-965a-4c05d8fc8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 've', 'been', 'waiting', 'for', 'this', 'course', 'my', 'whole', 'life', '.']\n",
      "[1045, 1005, 2310, 2042, 3403, 2005, 2023, 2607, 2026, 2878, 2166, 1012]\n",
      "tensor([[1045, 1005, 2310, 2042, 3403, 2005, 2023, 2607, 2026, 2878, 2166, 1012],\n",
      "        [1045, 1005, 2310, 2042, 3403, 2005, 2023, 2607, 2026, 2878, 2166, 1012]])\n",
      "tensor([[-2.7220,  2.7847],\n",
      "        [-2.7220,  2.7847]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_weight = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_weight)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_weight)\n",
    "\n",
    "sequence = \"I've been waiting for this course my  whole life.\"\n",
    "\n",
    "tokens = tok.tokenize(sequence)\n",
    "print(tokens)\n",
    "ids = tok.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "\n",
    "input_ids = torch.tensor([ids, ids]) ## <---\n",
    "print(input_ids)\n",
    "\n",
    "out = model(input_ids)\n",
    "print(out.logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
