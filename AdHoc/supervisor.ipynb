{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/custom-file-systems/efs/fs-0713103aada1ad94d_fsap-03d52ef0d5b91b6d3/LLM-World/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "pwd = %pwd\n",
    "env_path = os.path.join(pwd,'.env')\n",
    "\n",
    "load_dotenv(env_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://bms-openai-proxy-eus-prod.azu.bms.com/openai-urls.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('AZURE_OPENAI_BASEURL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'azure_region': 'australiaeast',\n",
       "  'deployment_name': 'dall-e-3',\n",
       "  'deployment_type': 'Standard',\n",
       "  'endpoint': 'https://bms-openai-services-australiaeast-1-nonprod.azu.bms.com',\n",
       "  'model_version': '3.0',\n",
       "  'requests_per_minute_across_bms': 12,\n",
       "  'tokens_per_minute_across_bms': 2000},\n",
       " {'azure_region': 'eastus',\n",
       "  'deployment_name': 'dall-e-3',\n",
       "  'deployment_type': 'Standard',\n",
       "  'endpoint': 'https://bms-openai-services-eastus-1-nonprod.azu.bms.com',\n",
       "  'model_version': '3.0',\n",
       "  'requests_per_minute_across_bms': 12,\n",
       "  'tokens_per_minute_across_bms': 2000},\n",
       " {'azure_region': 'swedencentral',\n",
       "  'deployment_name': 'dall-e-3',\n",
       "  'deployment_type': 'Standard',\n",
       "  'endpoint': 'https://bms-openai-services-swedencentral-1-nonprod.azu.bms.com',\n",
       "  'model_version': '3.0',\n",
       "  'requests_per_minute_across_bms': 12,\n",
       "  'tokens_per_minute_across_bms': 2000}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = requests.get(os.getenv('AZURE_OPENAI_BASEURL'))\n",
    "response.json()['nonprod'].keys()\n",
    "response.json()['nonprod']['dall-e-3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dall-e-3', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4o-audio-preview', 'gpt-4o-global', 'gpt-4o-mini-global', 'gpt-4o-regional', 'gpt-5', 'gpt-5-chat', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5.1', 'gpt-5.1-chat', 'gpt-audio', 'gpt-audio-mini', 'gpt-image-1', 'gpt-image-1-mini', 'model-router', 'o1', 'o3', 'o3-mini', 'o4-mini', 'text-embedding-3-large', 'text-embedding-3-small', 'text-embedding-ada-002'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_endpoint = {}\n",
    "for obj_name in response.json()['nonprod']:\n",
    "    model_endpoint[response.json()['nonprod'][obj_name][0]['deployment_name']]=response.json()['nonprod'][obj_name][0]['endpoint']\n",
    "    # print(response.json()['nonprod'][obj_name][0])\n",
    "    # print(response.json()['nonprod'][obj_name][0]['deployment_name'])\n",
    "    # print(response.json()['nonprod'][obj_name][0]['endpoint'])\n",
    "model_endpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.lib.azure.AzureOpenAI at 0x7f4eaf9a14d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def openai_llm(modle_id: str):\n",
    "    '''Create LangChain LLM object for Azure OpenAI llm'''\n",
    "    api_response = requests.get(os.getenv('AZURE_OPENAI_BASEURL'))\n",
    "    payload = api_response.json()\n",
    "\n",
    "    gllm = AzureChatOpenAI(\n",
    "        deployment_name=modle_id,  \n",
    "        openai_api_version=\"2024-12-01-preview\",\n",
    "        azure_endpoint=payload['nonprod'][modle_id][0]['endpoint'],\n",
    "        api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
    "        temperature=0)\n",
    "    return gllm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_calendar_event(\n",
    "    title:str,\n",
    "    start_time:str,\n",
    "    end_time:str,\n",
    "    atendees:list[str],\n",
    "    location:str=\"\"\n",
    ") -> str:\n",
    "    \"\"\"create calendar event\"\"\"\n",
    "    return f\"Created event: {title} from {start_time} to {end_time} with {len(atendees)} atendees.\"\n",
    "\n",
    "@tool\n",
    "def send_email(\n",
    "    to:list[str],\n",
    "    subject:str,\n",
    "    body:str,\n",
    "    cc:list[str]\n",
    ") -> str:\n",
    "    \"\"\"send an email via api\"\"\"\n",
    "    return f\"Email sent to {','.join(to)} - Subject: {subject}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_available_time_slots(\n",
    "    atendees:list[str],\n",
    "    date:str,\n",
    "    duration_minutes:int,\n",
    ")-> list[str]:\n",
    "    \"\"\"Check calendar availability for a given atendee on a specific date\"\"\"\n",
    "    return [\"09:00\",\"14:00\",\"16:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALENDAR_AGENT_PROMPT = (\n",
    "    \"You are a calendar scheduling assistant. \"\n",
    "    \"Parse natural language scheduling requests (eg, 'next Tuesday at 2pm') \"\n",
    "    \"into proper ISO datetime formats. \"\n",
    "    \"Use get_available_time_slots to check availability when needed. \"\n",
    "    \"Use create_calendar_event to schedule events. \"\n",
    "    \"Always confirm what was scheduled in your final response. \"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "calendar_agent = create_agent(\n",
    "    model,\n",
    "    tools=[create_calendar_event, get_available_time_slots],\n",
    "    system_prompt=CALENDAR_AGENT_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test agent\n",
    "\n",
    "query = \"Schedule a team meeting next Tuesday at 2pm for 1 hour\"\n",
    "\n",
    "## surface real-time response from agent\n",
    "for step in calendar_agent.stream(\n",
    "    {\"messages\":[{\"role\":\"user\",\"content\":query}]}, \n",
    "    #stream_mode=\"updates\" #emits an event after every step\n",
    "):\n",
    "    print(step.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytempkernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
